{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing and Machine Learning in Python\n",
    "\n",
    "This notebook covers data preprocessing, classification, and regression tasks using various Python libraries like `pandas`, `numpy`, and `scikit-learn`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.naive_bayes import CategoricalNB, GaussianNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "import seaborn as sns\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting String Values to Numeric ##\n",
    "\n",
    "### Properties ###\n",
    "- Finds out if any String Values are present in the dataset\n",
    "- If the variance is low, it uses LabelEncoder to transform the values \n",
    "- If the variance is high, it uses OneHotEncoder to transform the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoders = {}\n",
    "def stringToNumeric(df):\n",
    "    label_encoders = {}\n",
    "    onehot_encoders = {}\n",
    "    print(\"\\nChecking for String Values...\")\n",
    "    sleep(1)\n",
    "\n",
    "    string_count = 0\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            string_count = df[column].apply(lambda x: isinstance(x, str)).sum()\n",
    "            print(f\"\\nString Values in '{column}': {string_count}\")\n",
    "            \n",
    "            if string_count > 0:\n",
    "                unique_values = df[column].nunique()\n",
    "                print(f\"Unique Values in '{column}': {unique_values}\")\n",
    "                \n",
    "                if unique_values < 10:\n",
    "                    le = LabelEncoder()\n",
    "                    df[column] = le.fit_transform(df[column])\n",
    "                    label_encoders[column] = le\n",
    "                    print(f\"\\n'{column}' encoded using LabelEncoder.\")\n",
    "                else:\n",
    "                    ohe = OneHotEncoder(sparse=False, drop='first')\n",
    "                    encoded_columns = ohe.fit_transform(df[[column]])\n",
    "                    ohe_column_names = [f\"{column}_{cat}\" for cat in ohe.categories_[0][1:]]\n",
    "                    encoded_df = pd.DataFrame(encoded_columns, columns=ohe_column_names, index=df.index)\n",
    "                    df.drop(column, axis=1, inplace=True)\n",
    "                    df = pd.concat([df, encoded_df], axis=1)\n",
    "                    onehot_encoders[column] = ohe\n",
    "                    print(f\"\\n'{column}' encoded using OneHotEncoder.\")\n",
    "\n",
    "    if string_count == 0:\n",
    "        print(f\"\\nNo string values found in the Dataset\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Null Values ##\n",
    "### Properties: ###\n",
    "- Counts the number of Null Values in the Dataset\n",
    "- If none, returns the Dataframe as it is\n",
    "- If not null, and are either Float or Int values; Uses mean to fill them in\n",
    "- If not null, and are Strings; Uses mode to fill them in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nullToNumeric(df):\n",
    "    null_counts = df.isnull().sum()\n",
    "    total_nulls = null_counts.sum()\n",
    "    print(\"\\nChecking for Null Values...\")\n",
    "    sleep(1)\n",
    "\n",
    "    if total_nulls > 0:\n",
    "        print(f\"\\nTotal Number of Null Values: {total_nulls}\")\n",
    "        for column in df.columns:\n",
    "            null_count = null_counts[column]\n",
    "            if null_count > 0:\n",
    "                print(f\"\\nThe number of null values in the Column '{column}' are: {null_count}\")\n",
    "                if df[column].dtype in ['float64', 'int64']:\n",
    "                    fill_value = df[column].mean()\n",
    "                    print(f\"Filling nulls in '{column}' with mean: {fill_value:.2f}\")\n",
    "                else:\n",
    "                    fill_value = df[column].mode()[0]\n",
    "                    print(f\"Filling nulls in '{column}' with mode: '{fill_value}'\")\n",
    "                df[column] = df[column].fillna(fill_value)\n",
    "        print(\"\\nNull values handled successfully!\")\n",
    "    else:\n",
    "        print(\"\\nNo null values found in the Dataset\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis ##\n",
    "### Properties: ###\n",
    "- Compares every feature with the target\n",
    "- The feature with the highest correlation with the target is returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestFeature(df, targetCol):\n",
    "    print(f\"Calculating correlation of features with the feature {targetCol}\")\n",
    "    sleep(1)\n",
    "    correlations = df.corr()[targetCol].drop(targetCol)\n",
    "    best_feature = correlations.abs().idxmax()\n",
    "    max_correlation = correlations[best_feature]\n",
    "    print(f\"The feature best correlated with the target '{targetCol}' is '{best_feature}'\")\n",
    "    print(f\"Correlation coefficient: {max_correlation:.4f}\")\n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling ##\n",
    "- Analyzes the dataset to determine the appropriate scaling method\n",
    "- Excludes the target column\n",
    "- Finds out if the features are scalable \n",
    "- If the range of values is large or outliers are present, MinMaxScaler is used else StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(df, targetCol):\n",
    "    print(\"\\n--------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    print(\"Analyzing the dataset to determine the appropriate scaling method...\")\n",
    "    sleep(1)\n",
    "\n",
    "    # Select numeric columns excluding the target column\n",
    "    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "    if targetCol in numeric_cols:\n",
    "        numeric_cols.remove(targetCol)\n",
    "\n",
    "    if not numeric_cols:\n",
    "        print(\"No numeric columns to scale. Skipping scaling.\")\n",
    "        return df\n",
    "\n",
    "    # Analyze the range of the numeric columns\n",
    "    ranges = df[numeric_cols].max() - df[numeric_cols].min()\n",
    "\n",
    "    if ranges.max() > 10:  # Use MinMaxScaler if the range of values is large or there are outliers\n",
    "        print(\"\\nUsing MinMaxScaler due to the wide range of values.\")\n",
    "        scaler = MinMaxScaler()\n",
    "    else:  # Otherwise, use StandardScaler for standardization\n",
    "        print(\"\\nUsing StandardScaler for standardization.\")\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "    # Apply the chosen scaler\n",
    "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "    sleep(1)\n",
    "    print(\"\\nScaling complete!\")\n",
    "    print(f\"Scaled Columns: {numeric_cols}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying The Classification Model ##\n",
    "- Asks the user for the target column\n",
    "- Asks the user whether they want to scale the dataset or not\n",
    "- Separates the target feature and the best feature into 'y' & 'x' respectively\n",
    "- Shows plots in order to visualize the dataset\n",
    "- Uses either GaussianNB or CategoricalNB for the features\n",
    "    - GaussianNB for Continuous values\n",
    "    - CategoricalNB for Categorical values\n",
    "- Splits the data into Training & Testing splits (20 / 80)\n",
    "- Applies the Model\n",
    "- Predicts the values in the Testing Split\n",
    "- Uses Metrics to output the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createClassification(df):\n",
    "    targetCol = input(\"\\nWhat is the Target Column?: \").strip()\n",
    "    \n",
    "    if targetCol not in df.columns:\n",
    "        raise ValueError(f\"Column {targetCol} does not exist, try again\")\n",
    "\n",
    "    print(\"\\n--------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    scale_choice = None\n",
    "    while scale_choice not in ['yes', 'no']:\n",
    "        scale_choice = input(\"Do you want to scale the data? (yes/no): \").strip().lower()\n",
    "        if scale_choice not in ['yes', 'no']:\n",
    "            print(\"\\nInvalid input. Please type 'yes' or 'no'.\")\n",
    "\n",
    "    if scale_choice == 'yes':\n",
    "        df = scaling(df, targetCol)\n",
    "\n",
    "\n",
    "    best_feature = bestFeature(df, targetCol)\n",
    "    # SEPARATING THE TARGET COLUMN    \n",
    "    x = df[best_feature]\n",
    "    y = df[str(targetCol)]\n",
    "\n",
    "    # Visualization\n",
    "    print(\"\\n--------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    print(\"Visualizing the relationship between the best feature and the target...\")\n",
    "    sleep(0.5)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    if y.dtype in ['float64', 'int64']:  # If target is numeric\n",
    "        plt.scatter(x, y, alpha=0.7, color='blue')\n",
    "        plt.title(f\"Scatter Plot of '{best_feature}' vs '{targetCol}'\")\n",
    "        plt.xlabel(best_feature)\n",
    "        plt.ylabel(targetCol)\n",
    "    else:  # If target is categorical\n",
    "        sns.boxplot(x=y, y=x, palette=\"viridis\")\n",
    "        plt.title(f\"Box Plot of '{best_feature}' by '{targetCol}'\")\n",
    "        plt.xlabel(targetCol)\n",
    "        plt.ylabel(best_feature)\n",
    "\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    x = x.values.reshape(-1, 1)  # RESHAPING X INTO A 2D ARRAY\n",
    "\n",
    "    # Check if the feature values are continuous or discrete\n",
    "    print(\"\\n--------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    if np.issubdtype(df[best_feature].dtype, np.floating):  # Continuous data\n",
    "        print(\"Feature values are continuous. Using Gaussian Naive Bayes.\")\n",
    "        nbModel = GaussianNB()\n",
    "    else:  # Discrete data\n",
    "        print(\"Feature values are discrete. Using Categorical Naive Bayes.\")\n",
    "        nbModel = CategoricalNB()\n",
    "\n",
    "    # SPLITTING DATA\n",
    "    xTrain, xTest, yTrain, yTest = tts(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # APPLYING MODEL\n",
    "    nbModel.fit(xTrain, yTrain)\n",
    "\n",
    "    yPred = nbModel.predict(xTest)\n",
    "    results = pd.DataFrame({'Actual': yTest, 'Predicted': yPred})\n",
    "    print(results.head())\n",
    "\n",
    "    #METRICS\n",
    "    accuracy = accuracy_score(yTest, yPred)\n",
    "    conf_matrix = confusion_matrix(yTest, yPred)\n",
    "    class_report = classification_report(yTest, yPred, zero_division = 0)\n",
    "    \n",
    "    sleep(0.5)\n",
    "    print(\"\\n--------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    print(f\"ACCURACY SCORE: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    print(\"\\n--------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    print(\"CONFUSION MATRIX:\")\n",
    "    print(conf_matrix)\n",
    "    \n",
    "    print(\"\\n--------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    print(\"CLASSIFICATION REPORT:\")\n",
    "    print(class_report)\n",
    "    print(\"\\nNaive Bayes Classifier Model Trained!\")\n",
    "\n",
    "    return nbModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying The Regression Model ##\n",
    "- Asks the user for the target column\n",
    "- Asks the user whether they want to scale the dataset or not\n",
    "- Separates the target feature and the best feature into 'y' & 'x' respectively\n",
    "- Splits the data into Training & Testing splits (20 / 80)\n",
    "- Finds out the Coefficient and Intercept\n",
    "- Uses the LinearRegression Model\n",
    "- Applies the Model\n",
    "- Predicts the values in the Testing Split\n",
    "- Uses Metrics (MSE & R2 Score) to output the model's performance\n",
    "- Shows plots in order to visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRegression(df):\n",
    "    targetCol = input(\"\\nWhat is the Target Column?: \").strip()    \n",
    "    \n",
    "    if targetCol not in df.columns:\n",
    "        raise ValueError(f\"Column {targetCol} does not exist, try again\")     \n",
    "\n",
    "    print(\"\\n--------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    scale_choice = None\n",
    "    while scale_choice not in ['yes', 'no']:\n",
    "        scale_choice = input(\"Do you want to scale the data? (yes/no): \").strip().lower()\n",
    "        if scale_choice not in ['yes', 'no']:\n",
    "            print(\"\\nInvalid input. Please type 'yes' or 'no'.\")\n",
    "\n",
    "    if scale_choice == 'yes':\n",
    "        df = scaling(df, targetCol)\n",
    "\n",
    "    \n",
    "    best_feature = bestFeature(df, targetCol)\n",
    "    #SEPARATING THE TARGET COLUMN    \n",
    "    x = df[best_feature].values.reshape(-1, 1)\n",
    "    y = df[str(targetCol)]\n",
    "\n",
    "    #TRAINING\n",
    "    xTrain, xTest, yTrain, yTest = tts(x, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(xTrain, yTrain)\n",
    "\n",
    "    print(\"\\n--------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    # Display the coefficients\n",
    "    print(f\"Coefficient: {model.coef_[0]}\")\n",
    "    print(f\"Intercept: {model.intercept_}\\n\")\n",
    "\n",
    "    # Predict on the test set\n",
    "    yPred = model.predict(xTest)\n",
    "\n",
    "    results = pd.DataFrame({'Actual': yTest, 'Predicted': yPred})\n",
    "    sleep(1)\n",
    "    print(f\"RESULTS: \\n{results.head()}\")\n",
    "\n",
    "    mse = mean_squared_error(yTest, yPred)\n",
    "    r2 = r2_score(yTest, yPred)\n",
    "\n",
    "    sleep(0.5)\n",
    "    print(f\"\\nMean Squared Error: {mse}\")\n",
    "    print(f\"\\nR-squared: {r2}\")\n",
    "\n",
    "    # Visualization\n",
    "    print(\"\\n--------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    print(\"Visualizing the relationship between the best feature and the target...\")\n",
    "    sleep(0.5)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Use the original x before reshaping for plotting\n",
    "    plt.scatter(df[best_feature], df[targetCol], alpha=0.7, color='blue')\n",
    "    plt.xlabel(best_feature)\n",
    "    plt.ylabel(targetCol)\n",
    "    plt.title(f\"Scatter Plot of '{best_feature}' vs '{targetCol}'\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking User Inputs and Running the Program ##\n",
    "- Loads the CSV File and analyzes it, using the '.info()' function \n",
    "- Calls the stringToNumeric & nullToNumeric Functions\n",
    "- Asks the user to select between Classification & Regression\n",
    "- Error checking methods implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv(\"iris.csv\")\n",
    "    print(\"CSV file successfully loaded!\")\n",
    "    sleep(0.3)\n",
    "    print(\"\\nAnalyzing the Dataset...\")\n",
    "    sleep(1)\n",
    "    print()\n",
    "    print(df.info())\n",
    "\n",
    "    df = stringToNumeric(df)\n",
    "    df = nullToNumeric(df)\n",
    "\n",
    "    validChoice = False\n",
    "    while not validChoice:\n",
    "        choice = input(\"\\nChoose:\\n1. Classification\\n2. Regression\\n\")\n",
    "        match choice:\n",
    "                case '1':\n",
    "                    print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "                    classOutput = createClassification(df)\n",
    "                    validChoice = True\n",
    "                case '2':\n",
    "                    print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "                    createRegression(df)\n",
    "                    validChoice = True\n",
    "                case _:\n",
    "                    print(\"Incorrect Input, Try again\")\n",
    "\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(\"Error: The file is empty or not a valid CSV file.\")\n",
    "\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
